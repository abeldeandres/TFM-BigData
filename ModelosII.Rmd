---
title: "ModelosII"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(Encoding="UTF-8")

```

```{r , echo=FALSE, include=FALSE}
library(caTools)
library(caret)
library(randomForest)
library(nnet)
library(neuralnet)
library(party) #ctree
library(gbm)
library(rfUtilities)
library(NeuralNetTools)
library(e1071)
library(ada) #adaboost
library(corrplot)
library(pROC)
library(ROCR) 
library(mlbench)

rm(list = ls())
final <- read.csv("C:/Users/Abel de Andrés Gómez/OneDrive/TFM/TraumaticData.csv",na.strings=c("","NA"))
final$outcome<-as.factor(ifelse(final$outcome == "1", "F", "V"))


```
## TERMINOS GENERALES
### Matriz de confusión
  * Una matriz de confusión es una tabla que se usa a menudo para describir el rendimiento de un modelo de clasificación sobre en un conjunto de datos de prueba para los cuales se conocen los valores verdaderos.

  * Definamos ahora los términos más básicos para nuestro estudio:
    + Verdaderos Positivos (TP): estos son casos en los que predijimos que sí (van a fallecer), y sí fallecen.
    + Verdaderos Negativos (TN): Predijimos que no iban a fallecer, y los pacientes no fallecen.
    + Falsos Positivos (FP): Predijimos que sí iban a fallecer, pero en realidad no han fallecido.
    + Falsos Negativos (FN): Predijimos que no, pero en realidad tienen la enfermedad.
    
  * En nuestro estudio se ha tomado como positivo, el valor de "F", es decir, que el paciente fallezca.
  
  * Otra información a tener en cuenta en los siguientes graficos:
    + Reference V, Prediction V -> Verdaderos Negativos (TN).
    + Reference F, Prediction V -> Falsos Negativos (FN)
    + Reference V, Prediction F -> Falsos Positivos (FP)
    + Reference F, Prediction F -> Verdaderos Positivos (TP)
    
  * Estimadores de mejora
    + Para modelos de regresion
      + R2
      + Root mean Square error
      + Correlación de Spearman
    + Para modelos de clasificacion
      + Overall Accuracy
      + Kappa Statistics
      + Sensibilidad: nos indica la capacidad de nuestro estimador para dar como casos positivos los casos realmente positivos.Proporcion de fallecidos correctamente identificados. Si predice que fallece, entonces que realmente fallezca.
      +Especificidad:nos indica la capacidad de nuestro estimador para dar como casos negativos los casos realmente negativos (que los usuarios esten vivos); proporción de vivos correctamente identificados.
      
### OVERFITTING     
* El overfitting, tambien llamado sobreajuste: es el efecto que se da al entrenar de mas un algoritmo de aprendizaje, de este modo el algoritmo queda muy ajustado a caracteristicas muy especificas y por lo tanto, su respuesta a nuevos datos empeora.

* Existen distintas tecnicas para evitar el sobreajuste:
  + Cross-Validation: esta técnica consiste en dividir los datos en varios conjuntos de datos y luego elegir uno de los conjuntos para medir la precisión de la predicción "test" y el resto para entrenar.Concretamente se divide la muestra en K submuestras, de forma que se utilizan K-1 para estimar el modelo y la restante como submuestra de evaluación, este proceso se repite K veces, de forma que cada submuestra es utilizada una vez para evaluar el modelo y K-1 veces para el ajuste. 
  + Detención temprana: proporciona información sobre cuántas iteraciones se pueden ejecutar antes de que el algoritmo de aprendizaje comience a sobrepasar el límite.
  + Poda: Simplemente elimina los nodos que agregan poca capacidad de predicción para el problema en cuestión.
  + Regularización: introduce un término de costo a la hora de obtener más variables con la función objetivo. Intenta reducir a cero los coeficientes de muchas variables consiguiendo asi reducir el término de costo.
  
* https://www.r-project.org/conferences/useR-2013/Tutorials/kuhn/user_caret_2up.pdf

## Datos de entrenamiento y test
* En primer lugar, diviremos los datos en un conjunto de entreno (train) y un conjunto de pruebas (test). Tenemos 6930 registros por lo que el 30% son datos de prueba (2096) y el 70% datos de entrenamiento del modelo (4890).


```{r , echo=FALSE}
#Cambiamos la variable outcome a factor para trabajar con el modelo
set.seed(42)
ind<-sample.split(Y=final$outcome,SplitRatio =0.7)
train <- final[ind,]
test <- final[!ind,]

```

## REGRESION LOGISTICA 
### Usando todos los predictores
#### Usando Cross Validation 10-fold
* En primer lugar vamos a construir nuestro modelo de regresion logistica con los datos de entrenamiento.
```{r , echo=FALSE}
set.seed(42)
ctrl <- trainControl(method = "repeatedcv", number = 10, savePredictions = TRUE,classProbs=TRUE,
summaryFunction=twoClassSummary)
mod_fit <- train(outcome ~ .,data = train, method="glm", family="binomial",
                 trControl = ctrl, tuneLength = 5,metric="ROC")
summary(mod_fit)
```

* Una vez hecho esto, vamos a utilizar los datos de test para predecir el modelo que hemos construido y comprobaremos el ajuste de este.

```{r , echo=FALSE}
predCV = predict(mod_fit, newdata=test)
confusionMatrixCV<-confusionMatrix(data = predCV, reference = test$outcome,positive="F")
confusionMatrixCV
```

```{r , echo=FALSE}
fourfoldplot(confusionMatrixCV$table)
```

* Como podemos comprobar, el modelo se ajusta bastante bien, con un 76%. Dicho de otra forma, el modelo es capaz de predecir correctamente un 76% de los datos de los pacientes.

* A continuacion, vamos a utilizar la curva de ROC con los valores de pAUC:

```{r , echo=FALSE}
predCV = predict(mod_fit, newdata=test,type="prob")

plot.roc(test$outcome, predCV$F,          # data
         percent = TRUE,                    # show all values in percent
         partial.auc=c(100, 90), 
         partial.auc.correct=TRUE,          # define a partial AUC (pAUC)
         print.auc=TRUE,                    
         #display pAUC value on the plot with following options:
         print.auc.pattern = "Corrected pAUC (100-90%% SP):\n%.1f%%",
         print.auc.col = "#1c61b6",
         auc.polygon = TRUE, 
         auc.polygon.col = "#1c61b6",       # show pAUC as a polygon
         max.auc.polygon = TRUE, 
         max.auc.polygon.col = "#1c61b622", # also show the 100% polygon
         main = "Partial AUC (pAUC)")

plot.roc(test$outcome, predCV$F,
         percent = TRUE, 
         add = TRUE, 
         type = "n",                        # add to plot, but don't re-add the ROC itself (useless)
         partial.auc = c(100, 90), 
         partial.auc.correct = TRUE,
         partial.auc.focus = "se",          # focus pAUC on the sensitivity
         print.auc = TRUE, 
         print.auc.pattern = "Corrected pAUC (100-90%% SE):\n%.1f%%", 
         print.auc.col = "#008600",
         print.auc.y = 40,                  # do not print auc over the previous one
         auc.polygon = TRUE, 
         auc.polygon.col = "#008600",
         max.auc.polygon = TRUE, 
         max.auc.polygon.col = "#00860022")
```


### Eliminando los predictores "sex" y "cause""
* Al igual que hicimos en el modelo anterior, vamos a construir el modelo eliminando las variables de "sex" y "cause"

```{r , echo=FALSE}
set.seed(42)
ctrl <- trainControl(method = "repeatedcv", number = 10, savePredictions = TRUE,classProbs=TRUE,
summaryFunction=twoClassSummary)
mod_fit1 <- train(outcome ~ age+ec+eye+motor+verbal+pupils+phm+sah+oblt+mdls+hmt,data = train, method="glm", family="binomial",trControl = ctrl, tuneLength = 5,metric="ROC")
```

* Una vez hecho esto, vamos a utilizar los datos de test para predecir el modelo que hemos construido y comprobaremos el ajuste de este.
```{r , echo=FALSE}
predCV1 = predict(mod_fit1, newdata=test)
confusionMatrixCV1<-confusionMatrix(data = predCV1, reference = test$outcome,positive="F")
confusionMatrixCV1

```

```{r , echo=FALSE}
fourfoldplot(confusionMatrixCV1$table)
```

* Como podemos comprobar, aunque el AIC ha mejorado (reducido su valor) utilizando este modelo (sin las variables de sexo y causa) respecto al modelo con todas las variables, ha empeorado las prediciones.

* A continuacion, vamos a utilizar la curva de ROC con los valores de pAUC:
```{r , echo=FALSE}
predCV1 = predict(mod_fit1, newdata=test,type="prob")

plot.roc(test$outcome, predCV1$F,          # data
         percent = TRUE,                    # show all values in percent
         partial.auc=c(100, 90), 
         partial.auc.correct=TRUE,          # define a partial AUC (pAUC)
         print.auc=TRUE,                    
         #display pAUC value on the plot with following options:
         print.auc.pattern = "Corrected pAUC (100-90%% SP):\n%.1f%%",
         print.auc.col = "#1c61b6",
         auc.polygon = TRUE, 
         auc.polygon.col = "#1c61b6",       # show pAUC as a polygon
         max.auc.polygon = TRUE, 
         max.auc.polygon.col = "#1c61b622", # also show the 100% polygon
         main = "Partial AUC (pAUC)")

plot.roc(test$outcome, predCV1$F,
         percent = TRUE, 
         add = TRUE, 
         type = "n",                        # add to plot, but don't re-add the ROC itself (useless)
         partial.auc = c(100, 90), 
         partial.auc.correct = TRUE,
         partial.auc.focus = "se",          # focus pAUC on the sensitivity
         print.auc = TRUE, 
         print.auc.pattern = "Corrected pAUC (100-90%% SE):\n%.1f%%", 
         print.auc.col = "#008600",
         print.auc.y = 40,                  # do not print auc over the previous one
         auc.polygon = TRUE, 
         auc.polygon.col = "#008600",
         max.auc.polygon = TRUE, 
         max.auc.polygon.col = "#00860022")
```

## RANDOM FOREST u otros modelos de arboles (GBM, Adaboost, XGBM, etc.)

* Random forest es otra técnica de aprendizaje automático y nace como mejora sustancial de los árboles simples. Combina una cantidad grande de árboles de decisión independientes probados sobre conjuntos de datos aleatorios con igual distribución.

  * La fase de aprendizaje consiste en crear una gran cantidad de árboles de decisión independientes. Estos arboles se construyen a partir de los datos de entrada ligeramente modificados. Se modifica el conjunto inicial de partida, de la siguiente forma:

    + Se selecciona aleatoriamente con reemplazamiento un porcentaje de datos de la muestra total.

  * Es habitual incluir un segundo nivel aleatoriedad, esta vez afectando los atributos:

    + En cada nodo, al seleccionar la partición óptima, tenemos en cuenta sólo una porción de los atributos, elegidos al azar en cada ocasión.

  * Una vez que se tienen muchos árboles -500 por ejemplo- la fase de clasificación se lleva a cabo de la siguiente manera:

    + Cada árbol se evalúa de forma independiente y la predicción del bosque será la media de los 500 árboles. La proporción de árboles que toman una misma respuesta se interpreta como la probabilidad de la misma.

* El modelo de Random Forest tambien lo construiremos con los mismos datos de entrenamiento que utilizamos en la regresion logistica.

```{r , echo=FALSE}
set.seed(42)
model.RF=randomForest(outcome~.,data=train,ntree=500)
print(model.RF)
```

```{r , echo=FALSE}
mtry=tuneRF(x = train[,-14],       # data set de entrenamiento 
       y = train$outcome,  # variable a predecir
       mtryStart  = 1,   # cantidad de variables inicial 
       stepFactor = 2,   # incremento de variables
       ntreeTry   = 500, # cantidad arboles a ejecutar en cada iteracion
       improve    = .01  # mejora minina del OOB para seguir iteraciones
      )
best.m <- mtry[mtry[, 2] == min(mtry[, 2]), 1]
print(mtry)
```
* Utilizamos el siguiente valor como "mtry".
```{r , echo=FALSE}
print(best.m)
```
* Una vez obtenido el optimo valor de mtry, vamos a volver a construir el modelo con el mtry optimo.
```{r , echo=FALSE}
model.RF2=randomForest(outcome~.,data=train,importance=T,ntree=500, mtry=best.m)
print(model.RF)
```

* Despues de construir el modelo, vamos a utilizar los datos de test para predecirlo. Comprobaremos una vez mas el ajuste de este.

```{r , echo=FALSE}
predRF <- predict(model.RF2, newdata = test)
confusionMatrixRF<-confusionMatrix(data=predRF,reference=test$outcome,positive="F")
confusionMatrixRF
```

```{r , echo=FALSE}
fourfoldplot(confusionMatrixRF$table)
```

* A continuacion, vamos a utilizar la curva de ROC con los valores de pAUC:
```{r , echo=FALSE}
predRF <- predict(model.RF2, newdata = test, type="prob")

plot.roc(test$outcome, predRF[,1],          # data
         percent = TRUE,                    # show all values in percent
         partial.auc=c(100, 90), 
         partial.auc.correct=TRUE,          # define a partial AUC (pAUC)
         print.auc=TRUE,                    
         #display pAUC value on the plot with following options:
         print.auc.pattern = "Corrected pAUC (100-90%% SP):\n%.1f%%",
         print.auc.col = "#1c61b6",
         auc.polygon = TRUE, 
         auc.polygon.col = "#1c61b6",       # show pAUC as a polygon
         max.auc.polygon = TRUE, 
         max.auc.polygon.col = "#1c61b622", # also show the 100% polygon
         main = "Partial AUC (pAUC)")

plot.roc(test$outcome, predRF[,1],
         percent = TRUE, 
         add = TRUE, 
         type = "n",                        # add to plot, but don't re-add the ROC itself (useless)
         partial.auc = c(100, 90), 
         partial.auc.correct = TRUE,
         partial.auc.focus = "se",          # focus pAUC on the sensitivity
         print.auc = TRUE, 
         print.auc.pattern = "Corrected pAUC (100-90%% SE):\n%.1f%%", 
         print.auc.col = "#008600",
         print.auc.y = 40,                  # do not print auc over the previous one
         auc.polygon = TRUE, 
         auc.polygon.col = "#008600",
         max.auc.polygon = TRUE, 
         max.auc.polygon.col = "#00860022")
```


## Adaboost

* El algoritmo AdaBoost propone entrenar iterativamente una serie de clasificadores base, de tal modo que cada nuevo clasificador preste mayor atención a los datos clasificados erróneamente por los clasificadores anteriores, y combinarlos de tal modo que se obtenga un clasificador con elevadas prestaciones.

* Las caracteristicas que lo convierten en un buen metodo son: su capacidad de evadir el **overfitting** y su menor porcentaje de error a cambio de tener un error mayor durante el entrenamiento.

* En primer lugar vamos a utilizar el paquete de "caret" con el objetivo de encontrar el modelo optimo usando adaboost. Aplicaremos la validación cruzada, iterando 10 veces.

```{r , echo=FALSE}
set.seed(42)
trainControl <- trainControl(method="cv", number=10)
metric <- "Accuracy"
model.ada1 <- train(outcome~., data=train, method="ada", 
                  trControl=trainControl,metric=metric)
print(model.ada1)

```
```{r , echo=FALSE}
plot(model.ada1)
```

* Como se puede comprobar en el grafico anterior, con 3 iteraciones, conseguimos una mayor precision (0.767).
* Tambien podemos comprobar como el paquete caret nos indica cuales son los mejores parametros que debemos utilizar para obtener la mejor precision.

* Con estos parametros (numero de iteraciones, maxima profundidad y nu -parametro para truncar-) construimos nuestro modelo:

```{r , echo=FALSE}
set.seed(42)
model.ada<-ada(outcome~.,data=train,iter=150,nu=0.1,control=rpart.control(maxdepth=2))

print(model.ada)
```

```{r , echo=FALSE}
plot(model.ada)
```

* Despues de construir el modelo con los datos de entrenamiento y habiendo entrenado el modelo construido con los datos de prueba, obtenemos la matriz de confusion:

```{r , echo=FALSE}
adaboost.predict=predict(model.ada,test)
confusionMatrixAdaBoost<-confusionMatrix(data=model.ada$confusion,reference=test$outcome,positive="F")
confusionMatrixAdaBoost
```

```{r , echo=FALSE}
fourfoldplot(confusionMatrixAdaBoost$table)
```

* A continuacion, vamos a utilizar la curva de ROC con los valores de pAUC:

```{r , echo=FALSE}
adaboost.predict <- predict(model.ada, newdata = test, type="prob")

plot.roc(test$outcome, adaboost.predict[,1],          # data
         percent = TRUE,                    # show all values in percent
         partial.auc=c(100, 90), 
         partial.auc.correct=TRUE,          # define a partial AUC (pAUC)
         print.auc=TRUE,                    
         #display pAUC value on the plot with following options:
         print.auc.pattern = "Corrected pAUC (100-90%% SP):\n%.1f%%",
         print.auc.col = "#1c61b6",
         auc.polygon = TRUE, 
         auc.polygon.col = "#1c61b6",       # show pAUC as a polygon
         max.auc.polygon = TRUE, 
         max.auc.polygon.col = "#1c61b622", # also show the 100% polygon
         main = "Partial AUC (pAUC)")

plot.roc(test$outcome, adaboost.predict[,1],
         percent = TRUE, 
         add = TRUE, 
         type = "n",                        # add to plot, but don't re-add the ROC itself (useless)
         partial.auc = c(100, 90), 
         partial.auc.correct = TRUE,
         partial.auc.focus = "se",          # focus pAUC on the sensitivity
         print.auc = TRUE, 
         print.auc.pattern = "Corrected pAUC (100-90%% SE):\n%.1f%%", 
         print.auc.col = "#008600",
         print.auc.y = 40,                  # do not print auc over the previous one
         auc.polygon = TRUE, 
         auc.polygon.col = "#008600",
         max.auc.polygon = TRUE, 
         max.auc.polygon.col = "#00860022")
```

## GBM
* La idea general es obtener una secuencia de árboles (muy) simples, donde cada árbol sucesivo se construye con los residuos de predicción del árbol anterior.

* Una vez generado los arboles uno a uno, se suman las predicciones de los árboles individuales:

* D(x)= dtree1(x) + dtree2(x) + ...

*  El siguiente árbol de decisiones -dtree3- intenta reducir la diferencia entre la función objetivo f(x) y la predicción del conjunto actual al reconstruir el residuo (dtree1 +dtree2).

* Ademas, el siguiente árbol -dtree3- en el conjunto debe complementarse bien con los árboles existentes y minimizar el error de entrenamiento del conjunto.

* D(x) + dtree3(x) = f(x)

* Para acercarnos a una prediccion sin errores, entrenamos un árbol para reconstruir la diferencia entre la función objetivo y las predicciones actuales de un conjunto, esta diferencia se denomina residuo: 

* R(x)= f(x) - D(x)

* Como podemos observar, si el árbol de decisión reconstruye completamente R(x), todo el conjunto daria predicciones sin errores, es decir, predicciones exactas. Esto en la practica nunca sucede.

* Uno de los principales problemas de todos los algoritmos de aprendizaje automático es 'saber cuándo detenerse', es decir, cómo evitar que el algoritmo de aprendizaje se ajuste tanto, que probablemente no mejore la validez predictiva del modelo. Este problema también se conoce como el problema del sobreajuste (overfitting).

* Para establecer el limite de estos algoritmos, tenemos en cuenta la iteracion (numero de arboles) en la que se consigue un menor error.


* El modelo de GBM tambien lo construiremos con los mismos datos de entrenamiento que utilizamos en los modelos anteriores.

```{r , echo=FALSE}
#https://rpubs.com/omicsdata/gbm
set.seed(42)
fitControl = trainControl(method="cv", number=10)
metric <- "Accuracy"

modelGBM = train(outcome~., data=train, method="gbm",distribution="bernoulli",metric=metric, trControl=fitControl, verbose=F )

print(modelGBM)
```

```{r , echo=FALSE}
plot(modelGBM)
```

* Después de construir el modelo, vamos a predecir utilizando los datos de test, con el objetivo de obtener la precision de este.

```{r , echo=FALSE}
model.predictGBM = predict(modelGBM, test, na.action = na.pass)

confusionMatrixGBM<-confusionMatrix(data=model.predictGBM,reference=test$outcome,positive="F")
confusionMatrixGBM
```
```{r , echo=FALSE}
fourfoldplot(confusionMatrixGBM$table)
```


* A continuacion, vamos a utilizar la curva de ROC con los valores de pAUC:

```{r , echo=FALSE}
model.predictGBM = predict(modelGBM, test, type="prob")
plot.roc(test$outcome,model.predictGBM$F,          # data
         percent = TRUE,                    # show all values in percent
         partial.auc=c(100, 90), 
         partial.auc.correct=TRUE,          # define a partial AUC (pAUC)
         print.auc=TRUE,                    
         #display pAUC value on the plot with following options:
         print.auc.pattern = "Corrected pAUC (100-90%% SP):\n%.1f%%",
         print.auc.col = "#1c61b6",
         auc.polygon = TRUE, 
         auc.polygon.col = "#1c61b6",       # show pAUC as a polygon
         max.auc.polygon = TRUE, 
         max.auc.polygon.col = "#1c61b622", # also show the 100% polygon
         main = "Partial AUC (pAUC)")

plot.roc(test$outcome, model.predictGBM$F,
         percent = TRUE, 
         add = TRUE, 
         type = "n",                        # add to plot, but don't re-add the ROC itself (useless)
         partial.auc = c(100, 90), 
         partial.auc.correct = TRUE,
         partial.auc.focus = "se",          # focus pAUC on the sensitivity
         print.auc = TRUE, 
         print.auc.pattern = "Corrected pAUC (100-90%% SE):\n%.1f%%", 
         print.auc.col = "#008600",
         print.auc.y = 40,                  # do not print auc over the previous one
         auc.polygon = TRUE, 
         auc.polygon.col = "#008600",
         max.auc.polygon = TRUE, 
         max.auc.polygon.col = "#00860022")
```

## XGBOOST

  * XGBoost es la abreviatura de 'Extreme Gradient Boosting'. Esta basado en en el modelo original GBM (ya estudiado anteriormente).

  * A continuacion se muestran algunas de las ventajas de XGBOOST frente GBM:
    +Regularizacion: La implementacion de GBM no tiene regularizacion, lo que provoca que XGBOOST reduzca el sobreajuste.
    + Procesammiento paralelo: XGBoost implementa el procesamiento paralelo y es sorprendentemente más rápido en comparación con GBM.
    + Mayor flexibilidad: XGBoost permite a los usuarios definir objetivos de optimización personalizados y criterios de evaluación.
    + Manejo de valores perdidos: XGBoost tiene una rutina incorporada para manejar los valores perdidos.
    + Poda: El algoritmo GBM dejaría de dividir un nodo cuando encuentre una pérdida negativa en una división. Por lo tanto XGBoost es mas codicioso. XGBoost por otro lado hace divisiones hasta la **max_depth** especificada y luego comienza a podar el árbol hacia atrás y a eliminar divisiones de las cuales no hay ganancia positiva.
    + Incorpora Cross-Validation: XGBoost permite al usuario ejecutar una validación cruzada en cada iteración del proceso de "boosting" y, por lo tanto, es fácil obtener el número óptimo  de iteraciones de "boosting" en una sola ejecución. Con GBM tenemos que ejecutar una búsqueda en cuadrícula y solo se pueden probar valores limitados.

```{r , echo=FALSE}

ControlParamteres <- trainControl(method = "cv",
                                  number = 10, #usamos 5 fold cross-validation
                                  savePredictions = TRUE,
                                  classProbs = TRUE #give the probabilities for each class.Not just the class labels
)

 parametersGrid <-  expand.grid(eta = 0.1, 
                            colsample_bytree=c(0.5,0.7),
                            max_depth=c(3,6),
                            nrounds=100,
                            gamma=1,
                            min_child_weight=2,
                            subsample = 1
                            )
 modelxgboost <- train(outcome~., 
                  data = train,
                  method = "xgbTree",
                  trControl = ControlParamteres,
                  tuneGrid=parametersGrid)
 modelxgboost
```

* Ahora predecimos

```{r , echo=FALSE}
predXGB<-predict(modelxgboost,test)
#out_predGBOOST<-as.factor(ifelse(predictions > 0.5, 1, 0))
#levels(out_predGBOOST)=c("F","V")
confusionMatrixGBOOST<-confusionMatrix(data = predXGB, reference = test$outcome,positive="F")
confusionMatrixGBOOST
```

```{r , echo=FALSE}
fourfoldplot(confusionMatrixGBOOST$table)
```

```{r , echo=FALSE}
predXGB<-predict(modelxgboost,test,type="prob")
plot.roc(test$outcome,predXGB$F,          # data
         percent = TRUE,                    # show all values in percent
         partial.auc=c(100, 90), 
         partial.auc.correct=TRUE,          # define a partial AUC (pAUC)
         print.auc=TRUE,                    
         #display pAUC value on the plot with following options:
         print.auc.pattern = "Corrected pAUC (100-90%% SP):\n%.1f%%",
         print.auc.col = "#1c61b6",
         auc.polygon = TRUE, 
         auc.polygon.col = "#1c61b6",       # show pAUC as a polygon
         max.auc.polygon = TRUE, 
         max.auc.polygon.col = "#1c61b622", # also show the 100% polygon
         main = "Partial AUC (pAUC)")

plot.roc(test$outcome, predXGB$F,
         percent = TRUE, 
         add = TRUE, 
         type = "n",                        # add to plot, but don't re-add the ROC itself (useless)
         partial.auc = c(100, 90), 
         partial.auc.correct = TRUE,
         partial.auc.focus = "se",          # focus pAUC on the sensitivity
         print.auc = TRUE, 
         print.auc.pattern = "Corrected pAUC (100-90%% SE):\n%.1f%%", 
         print.auc.col = "#008600",
         print.auc.y = 40,                  # do not print auc over the previous one
         auc.polygon = TRUE, 
         auc.polygon.col = "#008600",
         max.auc.polygon = TRUE, 
         max.auc.polygon.col = "#00860022")
```

## Redes de neuronas

* Las redes neuronales son sistemas computacionales de aprendizaje basados en el funcionamiento de las redes neuronales biologicas presentes en el cerebro de los animales.

* Estas redes estan construidas a partir de una serie de nodos llamados "neuronas" que se organizan en forma de capas. Existe una capa de entrada, una capa de salida y al menos una capa intermedia o capa "oculta".

* La capa de entrada debe tener tantas neuronas como variables de entrada tenga el sistema que se va a modelar. La capa de salida debe tener tantas neuronas como variables que estemos intentando predecir, en nuestro caso solo una. 

* En cuanto a las capas ocultas, sus neuronas realizan transformaciones no lineales sobre la informacion que los atraviesa mediante una funcion de activacion. Las salidas de estas funciones de activacion suelen variar entre 0 y 1.  Estas neuronas se activan o no dependiendo de si la informacion que entra en estas neuronas Si la informacion que entra en esta neurona supera un valor umbral. 

* Las tareas de estas neuronas "ocultas" es realizar una suma ponderada de todas las entradas que tiene y aplicarle una funcion de activacion para posteriormente pasar este valor a las neuronas de la siguiente capa, que a su vez repetiran el proceso.

* En primer lugar, antes de comenzar con la construccion del modelo de redes neuronales, es necesario normalizar los datos. 

## Mejorar la precision de nuestro modelo

* Para poder obtener las mejores prediciones (precision) con nuestro modelo de redes neuronales, deberemos tener en cuenta aspectos como:
  + *Numero de capas ocultas*.
  + *Numero de neuronas por capa oculta:*  Si se usa una cantidad inadecuada de neuronas, la red no podrá modelar datos complejos y el ajuste resultante será deficiente. Si se utilizan demasiadas neuronas, el tiempo de entrenamiento puede ser excesivamente largo y, lo que es peor, la red puede sobreajustar los datos.No hay una regla práctica para elegir el número de neuronas, pero puede considerar esta:
    + N es el número de neuronas ocultas.
    + N = 2/3 del tamaño de la capa de entrada, más el tamaño de la capa de salida.
    + N < dos veces el tamaño de la capa de entrada.
  + *Funcion de activacion de las capas ocultas:* Cambiar la función de activación puede ser un factor decisivo.Se pueden probar distintas funciones de activacion: sigmoide, tanh y unidades lineales rectificadas.
  + *Funcion de activacion de las capas de salida:* Para una sola capa la elección de la función de activación para la capa de salida dependerá de la tarea que realizaremos con la red (es decir, categorización o regresión). Sin embargo, en redes multicapas, generalmente es deseable que las capas ocultas tengan funciones de activación no lineales (por ejemplo, sigmoide, logística o tanh).
  
### Usando todas las variables

```{r , echo=FALSE}
#Max-Min Normalization
normalize <- function(x) {
  return ((x - min(x)) / (max(x) - min(x)))
}
trainNorm<-train 
testNorm<-test

trainNorm$outcome<-as.numeric(trainNorm$outcome)
testNorm$outcome<-as.numeric(testNorm$outcome)

trainNorm <- as.data.frame(lapply(trainNorm, normalize))
testNorm <- as.data.frame(lapply(testNorm, normalize))

trainNorm$outcome<-train$outcome
testNorm$outcome<-test$outcome
```


```{r , echo=FALSE}
MCOR <- cor(final[,1:13])
col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD", "#4477AA"))
cex.before <- par("cex")
par(cex = 0.5)
corrplot(MCOR, method="color", col=col(200),  
         type="upper", order="hclust", 
         addCoef.col = "black", # Add coefficient of correlation
         tl.col="black", tl.srt=45, tl.cex = 1/par("cex"), #Text label color and rotation
         # hide correlation coefficient on the principal diagonal
         diag=FALSE 
         )


# calculate correlation matrix
correlationMatrix <- cor(final[,1:13])
# find attributes that are highly corrected (ideally >0.75)
highlyCorrelated <- findCorrelation(correlationMatrix, cutoff=0.50)
highlyCorrelated
```

* Para construir el modelo, una vez nos hemos ayudado con el paquete "Caret" y su validacion cruzada con 10 iteraciones.

* En la construccion del modelo, es necesario probar distintos parametros, concretamente dos que son:
  + Decay: es el parametro de los pesos.
  + Size: es el numero de capas ocultas.
  
* Estos valores, se han ido probando mediante "fuerza bruta" hasta obtener los mejores valores de ROC.El parametro de Decay se ha ido variando desde 0.1 hasta 0.5 en 0.1 unidades. El parametro de "Size" se ha ido variando desde 1 hasta 10 en 1 unidad.

```{r , echo=FALSE, include=FALSE}
set.seed(42)

fitControl <- trainControl(method = "repeatedcv", 
                           number = 10, 
                           repeats = 5, 
                           classProbs = TRUE, 
                           summaryFunction = twoClassSummary)
              
nnetGrid <-  expand.grid(size = 6,decay = 0.5)

model.nn <- train(outcome ~ ., 
                 data = trainNorm,
                 method = "nnet",
                 metric = "ROC",
                 trControl = fitControl,
                 tuneGrid = nnetGrid,
                 verbose = FALSE)
#SOFTNEX
#Neural net from caret only deals with regression and takes 3 params i.e. layers 1-3.
#print(model.nn)
```


```{r , echo=FALSE}
plotnet(model.nn, alpha=0.6)
```

```{r , echo=FALSE}
NNPredictions <-predict(model.nn, testNorm)

confusionMatrixNET<-confusionMatrix(data=NNPredictions,reference=test$outcome,positive="F")
confusionMatrixNET
```

```{r , echo=FALSE}
fourfoldplot(confusionMatrixNET$table)
```
```{r , echo=FALSE}
predNET1<-predict(model.nn,test,type="prob")
plot.roc(test$outcome,predNET1$F,          # data
         percent = TRUE,                    # show all values in percent
         partial.auc=c(100, 90), 
         partial.auc.correct=TRUE,          # define a partial AUC (pAUC)
         print.auc=TRUE,                    
         #display pAUC value on the plot with following options:
         print.auc.pattern = "Corrected pAUC (100-90%% SP):\n%.1f%%",
         print.auc.col = "#1c61b6",
         auc.polygon = TRUE, 
         auc.polygon.col = "#1c61b6",       # show pAUC as a polygon
         max.auc.polygon = TRUE, 
         max.auc.polygon.col = "#1c61b622", # also show the 100% polygon
         main = "Partial AUC (pAUC)")

plot.roc(test$outcome, predNET1$F,
         percent = TRUE, 
         add = TRUE, 
         type = "n",                        # add to plot, but don't re-add the ROC itself (useless)
         partial.auc = c(100, 90), 
         partial.auc.correct = TRUE,
         partial.auc.focus = "se",          # focus pAUC on the sensitivity
         print.auc = TRUE, 
         print.auc.pattern = "Corrected pAUC (100-90%% SE):\n%.1f%%", 
         print.auc.col = "#008600",
         print.auc.y = 40,                  # do not print auc over the previous one
         auc.polygon = TRUE, 
         auc.polygon.col = "#008600",
         max.auc.polygon = TRUE, 
         max.auc.polygon.col = "#00860022")
```

### Eliminamos las variables mas correladas: Verbal

```{r , echo=FALSE, include=FALSE}
set.seed(42)
trainNormCor <-trainNorm[,-7]
testNormCor <-testNorm[,-7]
fitControl <- trainControl(method = "repeatedcv", 
                           number = 10, 
                           repeats = 5, 
                           classProbs = TRUE, 
                           summaryFunction = twoClassSummary)
              
nnetGrid <-  expand.grid(size = 6,decay = 0.5)

model.nn2 <- train(outcome ~ ., 
                 data = trainNormCor,
                 method = "nnet",
                 metric = "ROC",
                 trControl = fitControl,
                 tuneGrid = nnetGrid,
                 verbose = FALSE)
#print(model.nn)
```

* Predecimos
```{r , echo=FALSE}
NNPredictions <-predict(model.nn2, testNormCor)

confusionMatrixNET<-confusionMatrix(data=NNPredictions,reference=testNormCor$outcome,positive="F")
confusionMatrixNET
```

```{r , echo=FALSE}
fourfoldplot(confusionMatrixNET$table)
```


```{r , echo=FALSE}
predNET2<-predict(model.nn2,testNormCor,type="prob")
plot.roc(testNormCor$outcome,predNET2$F,          # data
         percent = TRUE,                    # show all values in percent
         partial.auc=c(100, 90), 
         partial.auc.correct=TRUE,          # define a partial AUC (pAUC)
         print.auc=TRUE,                    
         #display pAUC value on the plot with following options:
         print.auc.pattern = "Corrected pAUC (100-90%% SP):\n%.1f%%",
         print.auc.col = "#1c61b6",
         auc.polygon = TRUE, 
         auc.polygon.col = "#1c61b6",       # show pAUC as a polygon
         max.auc.polygon = TRUE, 
         max.auc.polygon.col = "#1c61b622", # also show the 100% polygon
         main = "Partial AUC (pAUC)")

plot.roc(testNormCor$outcome, predNET2$F,
         percent = TRUE, 
         add = TRUE, 
         type = "n",                        # add to plot, but don't re-add the ROC itself (useless)
         partial.auc = c(100, 90), 
         partial.auc.correct = TRUE,
         partial.auc.focus = "se",          # focus pAUC on the sensitivity
         print.auc = TRUE, 
         print.auc.pattern = "Corrected pAUC (100-90%% SE):\n%.1f%%", 
         print.auc.col = "#008600",
         print.auc.y = 40,                  # do not print auc over the previous one
         auc.polygon = TRUE, 
         auc.polygon.col = "#008600",
         max.auc.polygon = TRUE, 
         max.auc.polygon.col = "#00860022")
```

## VALIDACION DE MODELOS

### Comparación de modelos de regresión


```{r , echo=FALSE, include=FALSE}
ctrl <- trainControl(method = "repeatedcv", number = 10, savePredictions = TRUE,classProbs=TRUE,
summaryFunction=twoClassSummary)
mod_fit_Complete <- train(outcome ~ .,data = train, method="glm", family="binomial",
                 trControl = ctrl, tuneLength = 5,metric="ROC")
mod_fit_1<- train(outcome ~ age+ec+verbal+hmt+motor+eye+oblt+mdls+sah+cause+pupils+sex,data = train, method="glm", family="binomial",
                 trControl = ctrl, tuneLength = 5,metric="ROC")

mod_fit_2<- train(outcome ~ age+ec+verbal+hmt+motor+eye+oblt+mdls+sah+cause+pupils,data = train, method="glm", family="binomial",
                 trControl = ctrl, tuneLength = 5,metric="ROC")
mod_fit_3<- train(outcome ~ age+ec+verbal+hmt+motor+eye+oblt+mdls+sah+cause,data = train, method="glm", family="binomial",
                 trControl = ctrl, tuneLength = 5,metric="ROC")
mod_fit_4<- train(outcome ~ age+ec+verbal+hmt+motor+eye+oblt+mdls+sah,data = train, method="glm", family="binomial",
                 trControl = ctrl, tuneLength = 5,metric="ROC")
mod_fit_5<- train(outcome ~ age+ec+verbal+hmt+motor+eye+oblt+mdls,data = train, method="glm", family="binomial",
                 trControl = ctrl, tuneLength = 5,metric="ROC")
mod_fit_6<- train(outcome ~ age+ec+verbal+hmt+motor+eye+oblt,data = train, method="glm", family="binomial",
                 trControl = ctrl, tuneLength = 5,metric="ROC")
mod_fit_7<- train(outcome ~ age+ec+verbal+hmt+motor+eye,data = train, method="glm", family="binomial",
                 trControl = ctrl, tuneLength = 5,metric="ROC")
mod_fit_8<- train(outcome ~ age+ec+verbal+hmt+motor,data = train, method="glm", family="binomial",
                 trControl = ctrl, tuneLength = 5,metric="ROC")
mod_fit_9<- train(outcome ~ age+ec+verbal+hmt,data = train, method="glm", family="binomial",
                 trControl = ctrl, tuneLength = 5,metric="ROC")
mod_fit_10<- train(outcome ~ age+ec+verbal,data = train, method="glm", family="binomial",
                 trControl = ctrl, tuneLength = 5,metric="ROC")
mod_fit_11<- train(outcome ~ age+ec,data = train, method="glm", family="binomial",
                 trControl = ctrl, tuneLength = 5,metric="ROC")
mod_fit_12<- train(outcome ~ age,data = train, method="glm", family="binomial",
                 trControl = ctrl, tuneLength = 5,metric="ROC")
dfarray <- list(mod_fit_Complete,mod_fit_1,mod_fit_2,mod_fit_3,mod_fit_4,mod_fit_5,mod_fit_6,mod_fit_7,mod_fit_8,mod_fit_9,mod_fit_10,mod_fit_11,mod_fit_11) 

aucSP = c()
aucSE= c()
for (i in dfarray){
  predIter<-predict(i,test,type="prob")
  auc1<-plot.roc(test$outcome,predIter$F,          # data
         percent = TRUE,                    # show all values in percent
         partial.auc=c(100, 90), 
         partial.auc.correct=TRUE,          # define a partial AUC (pAUC)
         print.auc=TRUE,                    
         #display pAUC value on the plot with following options:
         print.auc.pattern = "Corrected pAUC (100-90%% SP):\n%.1f%%",
         print.auc.col = "#1c61b6",
         auc.polygon = TRUE, 
         auc.polygon.col = "#1c61b6",       # show pAUC as a polygon
         max.auc.polygon = TRUE, 
         max.auc.polygon.col = "#1c61b622", # also show the 100% polygon
         main = "Partial AUC (pAUC)")
   auc2<-plot.roc(test$outcome, predIter$F,
         percent = TRUE, 
         add = TRUE, 
         type = "n",                        # add to plot, but don't re-add the ROC itself (useless)
         partial.auc = c(100, 90), 
         partial.auc.correct = TRUE,
         partial.auc.focus = "se",          # focus pAUC on the sensitivity
         print.auc = TRUE, 
         print.auc.pattern = "Corrected pAUC (100-90%% SE):\n%.1f%%", 
         print.auc.col = "#008600",
         print.auc.y = 40,                  # do not print auc over the previous one
         auc.polygon = TRUE, 
         auc.polygon.col = "#008600",
         max.auc.polygon = TRUE, 
         max.auc.polygon.col = "#00860022")
  aucSP<-c(aucSP, as.numeric(auc1$auc))
  aucSE<-c(aucSE, as.numeric(auc2$auc))
}
```
```{r , echo=FALSE}
nameVector<-c("mod_fit_Complete","mod_fit_1","mod_fit_2","mod_fit_3","mod_fit_4","mod_fit_5","mod_fit_6","mod_fit_7","mod_fit_8","mod_fit_9","mod_fit_10","mod_fit_11","mod_fit_12")
plot(aucSP,xaxt="n",type="b")
axis(1,at=1:13,labels=nameVector, las = 2)
```

```{r , echo=FALSE}
plot(aucSE,xaxt="n",type="b")
axis(1,at=1:13,labels=nameVector, las = 2)
```
