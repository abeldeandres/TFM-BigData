---
title: "ModelosII"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(Encoding="UTF-8")

```

```{r , echo=FALSE, include=FALSE}
library(caTools)
library(caret)
library(randomForest)
library(nnet)
library(neuralnet)
library(party) #ctree
library(gbm)
library(rfUtilities)
library(NeuralNetTools)
library(e1071)
library(adabag) #adaboost

rm(list = ls())
final <- read.csv("C:/Users/Abel de Andrés Gómez/OneDrive/TFM/TraumaticData.csv",na.strings=c("","NA"))
final$outcome<-as.factor(ifelse(final$outcome == "1", "F", "V"))


```
## TERMINOS GENERALES
### Matriz de confusión
  * Una matriz de confusión es una tabla que se usa a menudo para describir el rendimiento de un modelo de clasificación sobre en un conjunto de datos de prueba para los cuales se conocen los valores verdaderos.

  * Definamos ahora los términos más básicos para nuestro estudio:
    + Verdaderos Positivos (TP): estos son casos en los que predijimos que sí (van a fallecer), y sí fallecen.
    + Verdaderos Negativos (TN): Predijimos que no iban a fallecer, y los pacientes no fallecen.
    + Falsos Positivos (FP): Predijimos que sí iban a fallecer, pero en realidad no han fallecido.
    + Falsos Negativos (FN): Predijimos que no, pero en realidad tienen la enfermedad.
    
  * En nuestro estudio se ha tomado como positivo, el valor de "F", es decir, que el paciente fallezca.
  
  * Otra información a tener en cuenta en los siguientes graficos:
    + Reference V, Prediction V -> Verdaderos Negativos (TN).
    + Reference F, Prediction V -> Falsos Negativos (FN)
    + Reference V, Prediction F -> Falsos Positivos (FP)
    + Reference F, Prediction F -> Verdaderos Positivos (TP)
    
  * Estimadores de mejora
    + Para modelos de regresion
      + R2
      + Root mean Square error
      + Correlación de Spearman
    + Para modelos de clasificacion
      + Overall Accuracy
      + Kappa Statistics
      + Sensibilidad: nos indica la capacidad de nuestro estimador para dar como casos positivos los casos realmente positivos.Proporcion de fallecidos correctamente identificados. Si predice que fallece, entonces que realmente fallezca.
      +Especificidad:nos indica la capacidad de nuestro estimador para dar como casos negativos los casos realmente negativos (que los usuarios esten vivos); proporción de vivos correctamente identificados.
      
### OVERFITTING     
* El overfitting, tambien llamado sobreajuste: es el efecto que se da al entrenar de mas un algoritmo de aprendizaje, de este modo el algoritmo queda muy ajustado a caracteristicas muy especificas y por lo tanto, su respuesta a nuevos datos empeora.

* Existen distintas tecnicas para evitar el sobreajuste:
  + Cross-Validation: esta técnica consiste en dividir los datos en varios conjuntos de datos y luego elegir uno de los conjuntos para medir la precisión de la predicción "test" y el resto para entrenar.Concretamente se divide la muestra en K submuestras, de forma que se utilizan K-1 para estimar el modelo y la restante como submuestra de evaluación, este proceso se repite K veces, de forma que cada submuestra es utilizada una vez para evaluar el modelo y K-1 veces para el ajuste. 
  + Detención temprana: proporciona información sobre cuántas iteraciones se pueden ejecutar antes de que el algoritmo de aprendizaje comience a sobrepasar el límite.
  + Poda: Simplemente elimina los nodos que agregan poca capacidad de predicción para el problema en cuestión.
  + Regularización: introduce un término de costo a la hora de obtener más variables con la función objetivo. Intenta reducir a cero los coeficientes de muchas variables consiguiendo asi reducir el término de costo.
  
* https://www.r-project.org/conferences/useR-2013/Tutorials/kuhn/user_caret_2up.pdf

## Datos de entrenamiento y test
* En primer lugar, diviremos los datos en un conjunto de entreno (train) y un conjunto de pruebas (test). Tenemos 6930 registros por lo que el 30% son datos de prueba (2096) y el 70% datos de entrenamiento del modelo (4890).


```{r , echo=FALSE}
#Cambiamos la variable outcome a factor para trabajar con el modelo
final$outcome<-as.factor(final$outcome)
set.seed(42)
ind<-sample.split(Y=final$outcome,SplitRatio =0.7)
train <- final[ind,]
test <- final[!ind,]

```

## REGRESION LOGISTICA 
### Usando todos los predictores
* En primer lugar vamos a construir nuestro modelo de regresion logistica con los datos de entrenamiento.
```{r , echo=FALSE}
set.seed(42)
modelo.logit <- glm(outcome ~ ., 
                    data = train, family = "binomial")
summary(modelo.logit)
```

* Una vez hecho esto, vamos a utilizar los datos de test para predecir el modelo que hemos construido y comprobaremos el ajuste de este.
```{r , echo=FALSE}
options(warn=-1) 
pred <- predict(modelo.logit, newdata = test, type = "response")  # predicted probabilities
options(warn=1) 

out_pred_num <- ifelse(pred > 0.5, 1, 0)
#out_pred <- factor(out_pred_num, levels=c(0, 1))
out_pred<-as.factor(out_pred_num)
levels(out_pred)=c("F","V")
confusionMatrix<-confusionMatrix(data = out_pred, reference = test$outcome,positive="F")
confusionMatrix

```

```{r , echo=FALSE}
fourfoldplot(confusionMatrix$table)
```

* Como podemos comprobar, el modelo se ajusta bastante bien, con un 76%. Dicho de otra forma, el modelo es capaz de predecir correctamente un 76% de los datos de los pacientes.

#### Usando Cross Validation 10-fold

```{r , echo=FALSE}
ctrl <- trainControl(method = "repeatedcv", number = 10, savePredictions = TRUE)
mod_fit <- train(outcome ~ .,data = train, method="glm", family="binomial",
                 trControl = ctrl, tuneLength = 5)
```

* Una vez hecho esto, vamos a utilizar los datos de test para predecir el modelo que hemos construido y comprobaremos el ajuste de este.

```{r , echo=FALSE}
predCV = predict(mod_fit, newdata=test)
confusionMatrixCV<-confusionMatrix(data = predCV, reference = test$outcome,positive="F")
confusionMatrixCV
```

```{r , echo=FALSE}
fourfoldplot(confusionMatrix$table)
```


### Eliminando los predictores "sex" y "cause""
* Al igual que hicimos en el modelo anterior, vamos a construir el modelo eliminando las variables de "sex" y "cause"
```{r , echo=FALSE}
set.seed(42)
modelo.logit2 <- glm(outcome ~ age+ec+eye+motor+verbal+pupils+phm+sah+oblt+mdls+hmt, 
                    data = train, family = "binomial")
summary(modelo.logit2)
```

* Una vez hecho esto, vamos a utilizar los datos de test para predecir el modelo que hemos construido y comprobaremos el ajuste de este.
```{r , echo=FALSE}
options(warn=-1) 
pred2 <- predict(modelo.logit2, newdata = test, type = "response")  # predicted probabilities
options(warn=1) 

out_pred_num2 <- ifelse(pred2 > 0.5, 1, 0)
#out_pred2 <- factor(out_pred_num2, levels=c(0, 1))
out_pred2<-as.factor(out_pred_num2)
levels(out_pred2)=c("F","V")

confusionMatrix2<-confusionMatrix(data = out_pred2, reference = test$outcome,positive="F")
confusionMatrix2

```

```{r , echo=FALSE}
fourfoldplot(confusionMatrix2$table)
```

* Como podemos comprobar, aunque el AIC ha mejorado (reducido su valor) utilizando este modelo (sin las variables de sexo y causa) respecto al modelo con todas las variables, ha empeorado las prediciones.

## RANDOM FOREST u otros modelos de arboles (GBM, Adaboost, XGBM, etc.)

* Random forest es otra técnica de aprendizaje automático y nace como mejora sustancial de los árboles simples. Combina una cantidad grande de árboles de decisión independientes probados sobre conjuntos de datos aleatorios con igual distribución.

  * La fase de aprendizaje consiste en crear una gran cantidad de árboles de decisión independientes. Estos arboles se construyen a partir de los datos de entrada ligeramente modificados. Se modifica el conjunto inicial de partida, de la siguiente forma:

    + Se selecciona aleatoriamente con reemplazamiento un porcentaje de datos de la muestra total.

  * Es habitual incluir un segundo nivel aleatoriedad, esta vez afectando los atributos:

    + En cada nodo, al seleccionar la partición óptima, tenemos en cuenta sólo una porción de los atributos, elegidos al azar en cada ocasión.

  * Una vez que se tienen muchos árboles -500 por ejemplo- la fase de clasificación se lleva a cabo de la siguiente manera:

    + Cada árbol se evalúa de forma independiente y la predicción del bosque será la media de los 500 árboles. La proporción de árboles que toman una misma respuesta se interpreta como la probabilidad de la misma.

* El modelo de Random Forest tambien lo construiremos con los mismos datos de entrenamiento que utilizamos en la regresion logistica.

```{r , echo=FALSE}
set.seed(42)
model.RF=randomForest(outcome~.,data=train,ntree=500)
print(model.RF)
```

```{r , echo=FALSE}
train.RF<-train
train.RF$outcome<-as.numeric(train.RF$outcome)
mtry=tuneRF(x = train.RF,       # data set de entrenamiento 
       y = train.RF$outcome,  # variable a predecir
       mtryStart  = 1,   # cantidad de variables inicial 
       stepFactor = 2,   # incremento de variables
       ntreeTry   = 500, # cantidad arboles a ejecutar en cada iteracion
       improve    = .01  # mejora minina del OOB para seguir iteraciones
      )
best.m <- mtry[mtry[, 2] == min(mtry[, 2]), 1]
print(mtry)
```
* Utilizamos el siguiente valor como "mtry".
```{r , echo=FALSE}
print(best.m)
```
* Una vez obtenido el optimo valor de mtry, vamos a volver a construir el modelo con el mtry optimo.
```{r , echo=FALSE}
model.RF2=randomForest(outcome~.,data=final,importance=T,ntree=500, mtry=best.m)
print(model.RF)
```

* Despues de construir el modelo, vamos a utilizar los datos de test para predecirlo. Comprobaremos una vez mas el ajuste de este.

```{r , echo=FALSE}
predRF <- predict(model.RF2, newdata = test)
confusionMatrixRF<-confusionMatrix(data=predRF,reference=test$outcome,positive="F")
confusionMatrixRF
```

```{r , echo=FALSE}
fourfoldplot(confusionMatrixRF$table)
```


## Arbol de decisión
```{r , echo=FALSE}
set.seed(42)
train.ctree=ctree(outcome ~ age+ec+eye+motor+verbal+pupils+phm+sah+oblt+mdls+hmt+sex+cause, data=train)
#train.ctree
#plot(train.ctree, main="Árbol de decisión")
```
```{r , echo=FALSE}
ctree.predict=predict(train.ctree,test)
confusionMatrixCTREE<-confusionMatrix(data=ctree.predict,reference=test$outcome,positive="F")
confusionMatrixCTREE
```

```{r , echo=FALSE}
fourfoldplot(confusionMatrixCTREE$table)
```

## Adaboost

* El algoritmo AdaBoost propone entrenar iterativamente una serie de clasificadores base, de tal modo que cada nuevo clasificador preste mayor atención a los datos clasificados erróneamente por los clasificadores anteriores, y combinarlos de tal modo que se obtenga un clasificador con elevadas prestaciones.

* Las caracteristicas que lo convierten en un buen metodo son: su capacidad de evadir el **overfitting** y su menor porcentaje de error a cambio de tener un error mayor durante el entrenamiento.

```{r , echo=FALSE}
set.seed(42)
adaboost<-boosting(outcome ~ ., data=train, boos=TRUE, mfinal=20,coeflearn='Breiman')
#summary(adaboost)
```
* Despues de construir el modelo con los datos de entrenamiento y habiendo entrenado el modelo construido con los datos de prueba, obtenemos la matriz de confusion:

```{r , echo=FALSE}
adaboost.predict=predict(adaboost,test)
confusionMatrixAdaBoost<-confusionMatrix(data=as.factor(adaboost.predict$class),reference=test$outcome,positive="F")
confusionMatrixAdaBoost
```

```{r , echo=FALSE}
fourfoldplot(confusionMatrixAdaBoost$table)
```

## GBM
* La idea general es obtener una secuencia de árboles (muy) simples, donde cada árbol sucesivo se construye con los residuos de predicción del árbol anterior.

* Una vez generado los arboles uno a uno, se suman las predicciones de los árboles individuales:

* D(x)= dtree1(x) + dtree2(x) + ...

*  El siguiente árbol de decisiones -dtree3- intenta reducir la diferencia entre la función objetivo f(x) y la predicción del conjunto actual al reconstruir el residuo (dtree1 +dtree2).

* Ademas, el siguiente árbol -dtree3- en el conjunto debe complementarse bien con los árboles existentes y minimizar el error de entrenamiento del conjunto.

* D(x) + dtree3(x) = f(x)

* Para acercarnos a una prediccion sin errores, entrenamos un árbol para reconstruir la diferencia entre la función objetivo y las predicciones actuales de un conjunto, esta diferencia se denomina residuo: 

* R(x)= f(x) - D(x)

* Como podemos observar, si el árbol de decisión reconstruye completamente R(x), todo el conjunto daria predicciones sin errores, es decir, predicciones exactas. Esto en la practica nunca sucede.

* Uno de los principales problemas de todos los algoritmos de aprendizaje automático es 'saber cuándo detenerse', es decir, cómo evitar que el algoritmo de aprendizaje se ajuste tanto, que probablemente no mejore la validez predictiva del modelo. Este problema también se conoce como el problema del sobreajuste (overfitting).

* Para establecer el limite de estos algoritmos, tenemos en cuenta la iteracion (numero de arboles) en la que se consigue un menor error.


* El modelo de GBM tambien lo construiremos con los mismos datos de entrenamiento que utilizamos en los modelos anteriores.

```{r , echo=FALSE}
#https://rpubs.com/omicsdata/gbm
trainGBM<-train
trainGBM$outcome<-as.numeric(trainGBM$outcome)
trainGBM = transform(trainGBM, outcome=outcome-1)
set.seed(42)
model.gbm = gbm(outcome ~ ., data = trainGBM, shrinkage=0.01, distribution = 'bernoulli', cv.folds=5, n.trees=3000, verbose=F)
model.gbm
```

* A continuacion mostramos un grafico con la mejor iteracion para evitar el conocido sobreajuste (**overfitting**)

* Utilizando OOB

```{r , echo=FALSE}

best.iter.oob <- gbm.perf(model.gbm,method="OOB")  # returns out-of-bag estimated best number of trees
print(best.iter.oob)

```

* Utilizando Cross validation

```{r , echo=FALSE}

best.iter.cv <- gbm.perf(model.gbm,method="cv")   # returns 5-fold cv estimate of best number of trees
print(best.iter.cv)


```

* Hemos utilizado OOB ya que el numero de iteraciones es menor.

* Teniendo en cuenta el numero optimo de iteraciones, volvemos a crear el modelo con este numero:
```{r , echo=FALSE}
set.seed(42)
model.gbm = gbm(outcome ~ ., data = trainGBM, shrinkage=0.01, distribution = 'bernoulli', cv.folds=5, n.trees=best.iter.oob, verbose=F)
model.gbm
```

* El modelo tambien nos indica la importancia de los predictores:

```{r , echo=FALSE}
summary(model.gbm)
```

* Una vez mas, podemos comprobar que las variables "age" esta en la cabeza de las variables mas influyentes en el modelo y por el contrario la variable "sex", la que menos.


```{r , echo=FALSE}
model.predictGBM = predict(model.gbm, test, type="response")
out_pred_numGBM <- ifelse(model.predictGBM > 0.5, 1, 0)
#out_predGBM <- factor(out_pred_numGBM, levels=c(0, 1))
out_predGBM<-as.factor(out_pred_numGBM)
levels(out_predGBM)=c("F","V")
confusionMatrixGBM<-confusionMatrix(data = out_predGBM, reference = test$outcome,positive="F")
confusionMatrixGBM
```
```{r , echo=FALSE}
fourfoldplot(confusionMatrixGBM$table)
```



* Como conclusiones, utilizando OOB, hemos obtenido una mejor precision. Con Cross Validation obtuvimos un 0.7676527% de precision mientras que con OOB obtuvimos 0.7719%.

## XGBOOST
  * XGBoost es la abreviatura de 'Extreme Gradient Boosting'. Esta basado en en el modelo original GBM (ya estudiado anteriormente).

  * A continuacion se muestran algunas de las ventajas de XGBOOST frente GBM:
    +Regularizacion: La implementacion de GBM no tiene regularizacion, lo que provoca que XGBOOST reduzca el sobreajuste.
    + Procesammiento paralelo: XGBoost implementa el procesamiento paralelo y es sorprendentemente más rápido en comparación con GBM.
    + Mayor flexibilidad: XGBoost permite a los usuarios definir objetivos de optimización personalizados y criterios de evaluación.
    + Manejo de valores perdidos: XGBoost tiene una rutina incorporada para manejar los valores perdidos.
    + Poda: El algoritmo GBM dejaría de dividir un nodo cuando encuentre una pérdida negativa en una división. Por lo tanto XGBoost es mas codicioso. XGBoost por otro lado hace divisiones hasta la **max_depth** especificada y luego comienza a podar el árbol hacia atrás y a eliminar divisiones de las cuales no hay ganancia positiva.
    + Incorpora Cross-Validation: XGBoost permite al usuario ejecutar una validación cruzada en cada iteración del proceso de "boosting" y, por lo tanto, es fácil obtener el número óptimo  de iteraciones de "boosting" en una sola ejecución. Con GBM tenemos que ejecutar una búsqueda en cuadrícula y solo se pueden probar valores limitados.

```{r , echo=FALSE}

ControlParamteres <- trainControl(method = "cv",
                                  number = 5, #usamos 5 fold cross-validation
                                  savePredictions = TRUE,
                                  classProbs = TRUE #give the probabilities for each class.Not just the class labels
)

 parametersGrid <-  expand.grid(eta = 0.1, 
                            colsample_bytree=c(0.5,0.7),
                            max_depth=c(3,6),
                            nrounds=100,
                            gamma=1,
                            min_child_weight=2,
                            subsample = 1
                            )
 modelxgboost <- train(outcome~., 
                  data = train,
                  method = "xgbTree",
                  trControl = ControlParamteres,
                  tuneGrid=parametersGrid)
 modelxgboost
```
* Ahora predecimos
```{r , echo=FALSE}
predictions<-predict(modelxgboost,test)
#out_predGBOOST<-as.factor(ifelse(predictions > 0.5, 1, 0))
#levels(out_predGBOOST)=c("F","V")
confusionMatrixGBOOST<-confusionMatrix(data = predictions, reference = test$outcome,positive="F")
confusionMatrixGBOOST
```
```{r , echo=FALSE}
fourfoldplot(confusionMatrixGBOOST$table)
```

## Redes de neuronas

* Las redes neuronales son sistemas computacionales de aprendizaje basados en el funcionamiento de las redes neuronales biologicas presentes en el cerebro de los animales.

* Estas redes estan construidas a partir de una serie de nodos llamados "neuronas" que se organizan en forma de capas. Existe una capa de entrada, una capa de salida y al menos una capa intermedia o capa "oculta".

* La capa de entrada debe tener tantas neuronas como variables de entrada tenga el sistema que se va a modelar. La capa de salida debe tener tantas neuronas como variables que estemos intentando predecir, en nuestro caso solo una. 

* En cuanto a las capas ocultas, sus neuronas realizan transformaciones no lineales sobre la informacion que los atraviesa mediante una funcion de activacion. Las salidas de estas funciones de activacion suelen variar entre 0 y 1. Si la informacion que entra en esta neurona supera un valor umbral, esta se activa o no. 

* Las tareas de estas neuronas es realizar una suma ponderada de todas las entradas que tiene y aplicarle una funcion de activacion para posteriormente pasar el valor a las neuronas de la sigueinte capa, que a su vez repetiran el proceso.

* En primer lugar, antes de comenzar con la construccion del modelo de redes neuronales, es necesario normalizar los datos. 

```{r , echo=FALSE}
#Max-Min Normalization
normalize <- function(x) {
  return ((x - min(x)) / (max(x) - min(x)))
}
trainNorm<-train
testNorm<-test

trainNorm$outcome<-as.numeric(trainNorm$outcome)
testNorm$outcome<-as.numeric(testNorm$outcome)

trainNorm <- as.data.frame(lapply(trainNorm, normalize))
testNorm <- as.data.frame(lapply(testNorm, normalize))

trainNorm$outcome<-train$outcome
testNorm$outcome<-test$outcome
```


```{r , echo=FALSE}
set.seed(42)
model.nn = nnet(outcome ~ ., data = trainNorm, size = 2, rang = 0.1, maxit = 200)
print(model.nn)
```

```{r , echo=FALSE}
plotnet(model.nn, alpha=0.6)
```

```{r , echo=FALSE}
model.predictNET = predict(model.nn, testNorm)

#Si usamos factores
out_pred_numNET<-as.factor(ifelse(model.predictNET > 0.5, 1, 0))
levels(out_pred_numNET)=c("F","V")


confusionMatrixNET<-confusionMatrix(data=out_pred_numNET,reference=testNorm$outcome,positive="F")
confusionMatrixNET
```

```{r , echo=FALSE}
fourfoldplot(confusionMatrixNET$table)
```




